{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.tokenize import (\n",
    "    word_tokenize,\n",
    ")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               email  label\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n1  martin a posted tassos papadopoulos the greek ...      0\n2  man threatens explosion in moscow thursday aug...      0\n3  klez the virus that won t die already the most...      0\n4   in adding cream to spaghetti carbonara which ...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_or_not_spam.csv')\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   2999 non-null   object\n",
      " 1   label   3000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = df[df['email'].notna()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend('NUMBER')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def delete_digits(s):\n",
    "    return re.sub(\"[0-9]\", \"\", s)\n",
    "\n",
    "def delete_punkt(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation + \"«»—№–\"))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def normalize(text):\n",
    "    tokens = word_tokenize(text, 'english')\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens\n",
    "                  if token not in set(stop_words)]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "def preprocessing(text):\n",
    "    text_wo_numbers = delete_digits(text)\n",
    "    text_wo_punct = delete_punkt(text)\n",
    "    text_lem = normalize(text_wo_punct)\n",
    "    return text_lem"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               email  label  \\\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0   \n1  martin a posted tassos papadopoulos the greek ...      0   \n2  man threatens explosion in moscow thursday aug...      0   \n3  klez the virus that won t die already the most...      0   \n4   in adding cream to spaghetti carbonara which ...      0   \n\n                                       preproc_email  \n0  date wed NUMBER aug NUMBER NUMBER NUMBER NUMBE...  \n1  martin posted tasso papadopoulos greek sculpto...  \n2  man threatens explosion moscow thursday august...  \n3  klez virus die already prolific virus ever kle...  \n4  adding cream spaghetti carbonara effect pasta ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n      <th>preproc_email</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMBE...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n      <td>martin posted tasso papadopoulos greek sculpto...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n      <td>man threatens explosion moscow thursday august...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n      <td>klez virus die already prolific virus ever kle...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n      <td>adding cream spaghetti carbonara effect pasta ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preproc_email'] = df['email'].apply(preprocessing)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def custom_tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X = df['email']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# создаем выборку через CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_df=0.7, min_df=0.003, tokenizer=custom_tokenize)\n",
    "X_train_count_vectorizer = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count_vectorizer = count_vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# создаем выборку через Tf-Idf\n",
    "count_vectorizer = TfidfVectorizer(max_df=0.7, min_df=0.003, tokenizer=custom_tokenize)\n",
    "X_train_tfidf_vectorizer = count_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf_vectorizer = count_vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LogReg + TfIdf/CountVectorize pipelines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LogReg + Tfidf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_LR_TF = Pipeline(\n",
    "    steps=[\n",
    "        ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "        ('lr', LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_LR_TF = {\n",
    "    'vectorizer__min_df': [0.003, 0.00],\n",
    "    'vectorizer__max_df': [0.6, 0.7],\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__solver': ['liblinear', 'lbfgs', 'sag', 'saga'],\n",
    "    'lr__max_iter': [100, 150],\n",
    "    'lr__class_weight': [None, 'balanced'],\n",
    "    'lr__dual': [False],\n",
    "    'lr__tol': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "grid_pipeline_LR_TF = HalvingGridSearchCV(pipe_LR_TF, param_grid_LR_TF, verbose=1, n_jobs=-1)\n",
    "grid_pipeline_LR_TF.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr__C': 10,\n 'lr__class_weight': 'balanced',\n 'lr__dual': False,\n 'lr__max_iter': 100,\n 'lr__penalty': 'l2',\n 'lr__solver': 'saga',\n 'lr__tol': 0.001,\n 'vectorizer__max_df': 0.6,\n 'vectorizer__min_df': 0.0}"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline_LR_TF.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       821\n",
      "           1       0.99      0.93      0.96       169\n",
      "\n",
      "    accuracy                           0.99       990\n",
      "   macro avg       0.99      0.97      0.98       990\n",
      "weighted avg       0.99      0.99      0.99       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_tf = grid_pipeline_LR_TF.best_estimator_.predict(X_test)\n",
    "f1_lr_tf = f1_score(y_test, y_pred_lr_tf)\n",
    "print(classification_report(y_test, y_pred_lr_tf))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9634146341463414"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_lr_tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LogReg + CountVectorize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_LR_CVec = Pipeline(\n",
    "    steps=[\n",
    "        ('vectorizer', CountVectorizer(tokenizer=custom_tokenize)),\n",
    "        ('lr', LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_LR_CVec = {\n",
    "    'vectorizer__min_df': [0.003, 0.00],\n",
    "    'vectorizer__max_df': [0.6, 0.7],\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__solver': ['liblinear', 'lbfgs', 'sag', 'saga'],\n",
    "    'lr__max_iter': [100, 150],\n",
    "    'lr__class_weight': [None, 'balanced'],\n",
    "    'lr__dual': [False],\n",
    "    'lr__tol': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "grid_pipeline_LR_CVec = HalvingGridSearchCV(pipe_LR_CVec, param_grid_LR_CVec, verbose=1, n_jobs=-1)\n",
    "grid_pipeline_LR_CVec.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr__C': 0.1,\n 'lr__class_weight': 'balanced',\n 'lr__dual': False,\n 'lr__max_iter': 100,\n 'lr__penalty': 'l2',\n 'lr__solver': 'liblinear',\n 'lr__tol': 0.001,\n 'vectorizer__max_df': 0.7,\n 'vectorizer__min_df': 0.003}"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline_LR_CVec.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       821\n",
      "           1       0.99      0.96      0.98       169\n",
      "\n",
      "    accuracy                           0.99       990\n",
      "   macro avg       0.99      0.98      0.99       990\n",
      "weighted avg       0.99      0.99      0.99       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_cvec = grid_pipeline_LR_CVec.best_estimator_.predict(X_test)\n",
    "f1_lr_cvec = f1_score(y_test, y_pred_lr_cvec)\n",
    "print(classification_report(y_test, y_pred_lr_cvec))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сравнение моделей DecisionTree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "          DT+Tfidf HP   DT+Tfidf DT+CountVec\n0               lr__C        0.1          10\n1    lr__class_weight   balanced    balanced\n2            lr__dual      False       False\n3        lr__max_iter        100         100\n4         lr__penalty         l2          l2\n5          lr__solver  liblinear        saga\n6             lr__tol      0.001       0.001\n7  vectorizer__max_df        0.7         0.6\n8  vectorizer__min_df      0.003         0.0\n9            f1-score   0.975904    0.963415",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DT+Tfidf HP</th>\n      <th>DT+Tfidf</th>\n      <th>DT+CountVec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lr__C</td>\n      <td>0.1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>lr__class_weight</td>\n      <td>balanced</td>\n      <td>balanced</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lr__dual</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lr__max_iter</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lr__penalty</td>\n      <td>l2</td>\n      <td>l2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>lr__solver</td>\n      <td>liblinear</td>\n      <td>saga</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>lr__tol</td>\n      <td>0.001</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vectorizer__max_df</td>\n      <td>0.7</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>vectorizer__min_df</td>\n      <td>0.003</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>f1-score</td>\n      <td>0.975904</td>\n      <td>0.963415</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_dict = {\n",
    "    'DT+Tfidf HP': list(grid_pipeline_LR_CVec.best_params_.keys())+['f1-score'],\n",
    "    'DT+Tfidf': list(grid_pipeline_LR_CVec.best_params_.values())+[f1_lr_cvec],\n",
    "    'DT+CountVec':list(grid_pipeline_LR_TF.best_params_.values())+[f1_lr_tf]\n",
    "}\n",
    "nb = pd.DataFrame.from_dict(nb_dict)\n",
    "nb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DecisionTree + TfIdf/CountVectorize pipelines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DecisionTree + CountVectorize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_dt_cvec = Pipeline(\n",
    "        steps=[\n",
    "            ('vectorizer', CountVectorizer(tokenizer=custom_tokenize)),\n",
    "            ('dt', DecisionTreeClassifier())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid_dt_cvec = {\n",
    "    'vectorizer__min_df': [0.003, 0.05],\n",
    "    'vectorizer__max_df': [0.6, 0.7],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [10, 20],\n",
    "    'dt__min_samples_split': [2, 5],\n",
    "    'dt__min_samples_leaf': [2, 5],\n",
    "    'dt__max_features': ['auto', 'log2'],\n",
    "    'dt__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "grid_search_dt_cv = HalvingGridSearchCV(pipe_dt_cvec, param_grid_dt_cvec, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_dt_cv.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "{'dt__class_weight': 'balanced',\n 'dt__criterion': 'entropy',\n 'dt__max_depth': 10,\n 'dt__max_features': 'log2',\n 'dt__min_samples_leaf': 2,\n 'dt__min_samples_split': 2,\n 'vectorizer__max_df': 0.7,\n 'vectorizer__min_df': 0.05}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_dt_cv.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       821\n",
      "           1       0.69      0.77      0.73       169\n",
      "\n",
      "    accuracy                           0.90       990\n",
      "   macro avg       0.82      0.85      0.83       990\n",
      "weighted avg       0.91      0.90      0.90       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt_cvec = grid_search_dt_cv.best_estimator_.predict(X_test)\n",
    "f1_dt_cvec = f1_score(y_test, y_pred_dt_cvec)\n",
    "print(classification_report(y_test, y_pred_dt_cvec))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DecisionTree + TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_dt_tf = Pipeline(\n",
    "    steps=[\n",
    "        ('vectorizer', TfidfVectorizer(tokenizer=custom_tokenize)),\n",
    "        ('dt', DecisionTreeClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_dt_tf = {\n",
    "    'vectorizer__min_df': [0.003, 0.05],\n",
    "    'vectorizer__max_df': [0.6, 0.7],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [10, 20],\n",
    "    'dt__min_samples_split': [2, 5],\n",
    "    'dt__min_samples_leaf': [2, 5],\n",
    "    'dt__max_features': ['auto', 'log2'],\n",
    "    'dt__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "grid_search_dt_tf = HalvingGridSearchCV(pipe_dt_tf, param_grid_dt_tf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_dt_tf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "{'dt__class_weight': 'balanced',\n 'dt__criterion': 'gini',\n 'dt__max_depth': 20,\n 'dt__max_features': 'log2',\n 'dt__min_samples_leaf': 2,\n 'dt__min_samples_split': 5,\n 'vectorizer__max_df': 0.7,\n 'vectorizer__min_df': 0.05}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_dt_tf.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       821\n",
      "           1       0.69      0.77      0.73       169\n",
      "\n",
      "    accuracy                           0.90       990\n",
      "   macro avg       0.82      0.85      0.83       990\n",
      "weighted avg       0.91      0.90      0.90       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt_tf = grid_search_dt_cv.best_estimator_.predict(X_test)\n",
    "f1_dt_tf = f1_score(y_test, y_pred_dt_tf)\n",
    "print(classification_report(y_test, y_pred_dt_tf))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сравнение моделей DecisionTree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "             DT+Tfidf HP  DT+Tfidf DT+CountVec\n0       dt__class_weight  balanced    balanced\n1          dt__criterion      gini     entropy\n2          dt__max_depth        20          10\n3       dt__max_features      log2        log2\n4   dt__min_samples_leaf         2           2\n5  dt__min_samples_split         5           2\n6     vectorizer__max_df       0.7         0.7\n7     vectorizer__min_df      0.05        0.05\n8               f1-score  0.726257    0.726257",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DT+Tfidf HP</th>\n      <th>DT+Tfidf</th>\n      <th>DT+CountVec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dt__class_weight</td>\n      <td>balanced</td>\n      <td>balanced</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dt__criterion</td>\n      <td>gini</td>\n      <td>entropy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dt__max_depth</td>\n      <td>20</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dt__max_features</td>\n      <td>log2</td>\n      <td>log2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dt__min_samples_leaf</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>dt__min_samples_split</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>vectorizer__max_df</td>\n      <td>0.7</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vectorizer__min_df</td>\n      <td>0.05</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>f1-score</td>\n      <td>0.726257</td>\n      <td>0.726257</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_dict = {\n",
    "    'DT+Tfidf HP': list(grid_search_dt_tf.best_params_.keys())+['f1-score'],\n",
    "    'DT+Tfidf': list(grid_search_dt_tf.best_params_.values())+[f1_dt_tf],\n",
    "    'DT+CountVec':list(grid_search_dt_cv.best_params_.values())+[f1_dt_cvec]\n",
    "}\n",
    "nb = pd.DataFrame.from_dict(nb_dict)\n",
    "nb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MultinomialNB + TfIdf/CountVectorize pipelines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MultinomialNB + Tdidf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_nb_tf = Pipeline(\n",
    "    steps=[\n",
    "        ('vectorizer', TfidfVectorizer(tokenizer=custom_tokenize)),\n",
    "        ('nb', MultinomialNB())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_nb_tf = {\n",
    "    'vectorizer__min_df': [0.002, 0.003],\n",
    "    'vectorizer__max_df': [0.5, 0.6, 0.7],\n",
    "    'nb__alpha': [0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "grid_search_nb_tf = HalvingGridSearchCV(pipe_nb_tf, param_grid_nb_tf, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search_nb_tf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "{'nb__alpha': 0.1, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 0.002}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nb_tf.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       821\n",
      "           1       0.99      0.89      0.94       169\n",
      "\n",
      "    accuracy                           0.98       990\n",
      "   macro avg       0.99      0.95      0.96       990\n",
      "weighted avg       0.98      0.98      0.98       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb_tf = grid_search_nb_tf.best_estimator_.predict(X_test)\n",
    "f1_nb_tf = f1_score(y_test, y_pred_nb_tf)\n",
    "print(classification_report(y_test, y_pred_nb_tf))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MultinomialNB + CountVectorize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_nb_cvec = Pipeline(\n",
    "    steps=[\n",
    "        ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),\n",
    "        ('nb', MultinomialNB())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_nb_cvec = {\n",
    "    'vectorizer__min_df': [0.002, 0.003],\n",
    "    'vectorizer__max_df': [0.5, 0.6, 0.7],\n",
    "    'nb__alpha': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "}\n",
    "\n",
    "grid_search_nb_cvec = HalvingGridSearchCV(pipe_nb_cvec, param_grid_nb_cvec, cv=5, scoring='f1', n_jobs=-1, refit=True)\n",
    "grid_search_nb_cvec.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "{'nb__alpha': 0.1, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 0.003}"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nb_cvec.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9604899771108701"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nb_cvec.best_score_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       821\n",
      "           1       1.00      0.93      0.97       169\n",
      "\n",
      "    accuracy                           0.99       990\n",
      "   macro avg       0.99      0.97      0.98       990\n",
      "weighted avg       0.99      0.99      0.99       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb_cvec = grid_search_nb_cvec.best_estimator_.predict(X_test)\n",
    "f1_nb_cvec = f1_score(y_test, y_pred_nb_cvec)\n",
    "print(classification_report(y_test, y_pred_nb_cvec))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9663608562691132"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_nb_cvec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сравнение моделей NaiveBayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "          NB+Tfidf HP  NB+Tfidf  NB+CountVec\n0           nb__alpha   0.10000     0.100000\n1  vectorizer__max_df   0.50000     0.500000\n2  vectorizer__min_df   0.00200     0.003000\n3            f1-score   0.94081     0.966361",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NB+Tfidf HP</th>\n      <th>NB+Tfidf</th>\n      <th>NB+CountVec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nb__alpha</td>\n      <td>0.10000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vectorizer__max_df</td>\n      <td>0.50000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vectorizer__min_df</td>\n      <td>0.00200</td>\n      <td>0.003000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f1-score</td>\n      <td>0.94081</td>\n      <td>0.966361</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_dict = {\n",
    "    'NB+Tfidf HP': list(grid_search_nb_tf.best_params_.keys())+['f1-score'],\n",
    "    'NB+Tfidf': list(grid_search_nb_tf.best_params_.values())+[f1_nb_tf],\n",
    "    'NB+CountVec':list(grid_search_nb_cvec.best_params_.values())+[f1_nb_cvec]\n",
    "}\n",
    "nb = pd.DataFrame.from_dict(nb_dict)\n",
    "nb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Сравнение всех моделей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "                Model  F1 score\n0         LogReg + TF  0.963415\n1   LogReg + CountVec  0.975904\n2        DecTree + TF  0.726257\n3  DecTree + CountVec  0.726257\n4             NB + TF  0.940810\n5       NB + CountVec  0.966361",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>F1 score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogReg + TF</td>\n      <td>0.963415</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LogReg + CountVec</td>\n      <td>0.975904</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DecTree + TF</td>\n      <td>0.726257</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecTree + CountVec</td>\n      <td>0.726257</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NB + TF</td>\n      <td>0.940810</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NB + CountVec</td>\n      <td>0.966361</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict = {\n",
    "    'Model':['LogReg + TF', 'LogReg + CountVec', 'DecTree + TF', 'DecTree + CountVec', 'NB + TF', 'NB + CountVec'],\n",
    "    'F1 score': [f1_lr_tf, f1_lr_cvec, f1_dt_tf, f1_dt_cvec, f1_nb_tf, f1_nb_cvec],\n",
    "}\n",
    "res = pd.DataFrame.from_dict(res_dict)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
